{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba7d5b2c",
   "metadata": {},
   "source": [
    "#  Database Architecture Documentation\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Overview](#overview)\n",
    "2. [Quick Start](#quick-start)\n",
    "3. [Database Schema Architecture](#database-schema-architecture)\n",
    "4. [Infrastructure Analysis](#infrastructure-analysis)\n",
    "5. [Table Specifications](#table-specifications)\n",
    "6. [Performance & Optimization](#performance--optimization)\n",
    "7. [System Integration](#system-integration)\n",
    "8. [Commands Reference](#commands-reference)\n",
    "9. [Monitoring & Maintenance](#monitoring--maintenance)\n",
    "10. [Database Statistics & Capacity](#database-statistics-&-capacity)\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "The MediAgent Discovery Hub utilizes a **PostgreSQL-based architecture** specifically designed for AI-powered drug discovery workflows. Our database serves as the central nervous system for multi-agent pharmaceutical research, handling everything from molecular data storage to AI analysis results with enterprise-grade performance and reliability.\n",
    "\n",
    "### Key Features\n",
    "\n",
    "- **🔬 Pharmaceutical Data Focus**: Optimized schema for compounds, bioactivities, and AI predictions\n",
    "- **🤖 Multi-Agent Ready**: Designed for collaborative AI system integration\n",
    "- **⚡ High Performance**: Sub-millisecond compound lookups with intelligent indexing\n",
    "- **🔒 Data Integrity**: Complete audit trails and ACID compliance for regulatory requirements\n",
    "- **☁️ Cloud-Native**: Google Cloud Platform compatible with enterprise scalability\n",
    "\n",
    "### System Requirements\n",
    "\n",
    "- **Database**: PostgreSQL 15+ (containerized)\n",
    "- **Memory**: 16GB+ RAM for optimal performance\n",
    "- **Storage**: 100GB+ available space (SSD recommended)\n",
    "- **Network**: Docker container networking for service integration\n",
    "\n",
    "---\n",
    "\n",
    "## Quick Start\n",
    "\n",
    "### 1. Database Connection\n",
    "\n",
    "```bash\n",
    "# Connect to PostgreSQL container\n",
    "docker exec -it mediagent-postgres psql -U admin -d mediagent\n",
    "\n",
    "# Alternative: One-line connection with command\n",
    "docker exec -it mediagent-postgres psql -U admin -d mediagent -c \"\\dt\"\n",
    "```\n",
    "\n",
    "### 2. Essential Commands\n",
    "\n",
    "```sql\n",
    "-- 📋 Database Overview\n",
    "\\l                          -- List all databases\n",
    "\\dt                         -- List all tables\n",
    "\\du                         -- List all users\n",
    "\\q                          -- Exit PostgreSQL CLI\n",
    "\n",
    "-- 🔍 Table Inspection\n",
    "\\d compounds                -- Show table structure\n",
    "\\d+ compounds               -- Show detailed table info with size\n",
    "\\di                         -- List all indexes\n",
    "```\n",
    "\n",
    "### 3. Quick Health Check\n",
    "\n",
    "```sql\n",
    "-- Verify all tables exist\n",
    "SELECT table_name FROM information_schema.tables WHERE table_schema = 'public';\n",
    "\n",
    "-- Check data counts\n",
    "SELECT \n",
    "    'compounds' as table_name, COUNT(*) as row_count FROM compounds\n",
    "UNION ALL\n",
    "SELECT \n",
    "    'bioactivities' as table_name, COUNT(*) as row_count FROM bioactivities\n",
    "UNION ALL\n",
    "SELECT \n",
    "    'analysis_results' as table_name, COUNT(*) as row_count FROM analysis_results;\n",
    "```\n",
    "\n",
    "### 4. Sample Data Query\n",
    "\n",
    "```sql\n",
    "-- Preview compound data\n",
    "SELECT \n",
    "    id, \n",
    "    chembl_id, \n",
    "    compound_name, \n",
    "    molecular_formula, \n",
    "    molecular_weight \n",
    "FROM compounds \n",
    "LIMIT 5;\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Database Schema Architecture\n",
    "\n",
    "### System Overview\n",
    "\n",
    "```\n",
    "MediAgent Database Architecture\n",
    "├── Core Tables (3)\n",
    "│   ├── compounds (Molecular repository)\n",
    "│   ├── bioactivities (Experimental data)\n",
    "│   └── analysis_results (AI predictions)\n",
    "├── Indexes (Performance optimization)\n",
    "├── Relationships (Foreign key constraints)\n",
    "└── Monitoring (Statistics & health checks)\n",
    "```\n",
    "\n",
    "### Data Flow Architecture\n",
    "\n",
    "```\n",
    "📥 External Data Sources\n",
    "    ├── ChEMBL API → compounds table\n",
    "    ├── PubChem API → compounds table\n",
    "    └── Literature → bioactivities table\n",
    "                ↓\n",
    "🔄 n8n Orchestration Layer\n",
    "    ├── Data Validation Workflows\n",
    "    ├── Duplicate Detection\n",
    "    └── Data Quality Checks\n",
    "                ↓\n",
    "🗄️ PostgreSQL Database\n",
    "    ├── compounds (molecular data)\n",
    "    ├── bioactivities (experimental data)\n",
    "    └── analysis_results (AI predictions)\n",
    "                ↓\n",
    "🤖 AI Agent Processing\n",
    "    ├── Ollama LLMs → analysis_results\n",
    "    ├── DeepSeek-R1 → predictions\n",
    "    └── Llama 3.3 → analysis\n",
    "                ↓\n",
    "⚡ Redis Cache Layer\n",
    "    ├── Frequent queries\n",
    "    ├── Agent communication\n",
    "    └── Real-time results\n",
    "```\n",
    "\n",
    "### Resource Allocation\n",
    "\n",
    "| Component | Storage | Memory | Purpose |\n",
    "|-----------|---------|---------|---------|\n",
    "| **compounds** | 2-5 GB | 200-500 MB | Molecular structures |\n",
    "| **bioactivities** | 5-15 GB | 500 MB-1 GB | Experimental data |\n",
    "| **analysis_results** | 10-50 GB | 1-2 GB | AI predictions |\n",
    "| **Indexes** | 1-3 GB | 100-300 MB | Query optimization |\n",
    "\n",
    "---\n",
    "\n",
    "## Infrastructure Analysis\n",
    "\n",
    "### Current Implementation Status\n",
    "\n",
    "When properly deployed, the database infrastructure shows:\n",
    "\n",
    "| Component | Status | Configuration | Purpose |\n",
    "|-----------|--------|---------------|---------|\n",
    "| **PostgreSQL Container** | ✅ Running | postgres:15 | Primary database |\n",
    "| **Database: mediagent** | ✅ Created | UTF-8 encoding | Main database |\n",
    "| **User: admin** | ✅ Active | Full privileges | Database admin |\n",
    "| **Schema: public** | ✅ Ready | 3 tables + indexes | Core schema |\n",
    "\n",
    "### Storage Breakdown\n",
    "\n",
    "```\n",
    "Total Database Storage: ~25-75 GB (production scale)\n",
    "├── Table Data (20-60 GB)\n",
    "│   ├── compounds: 2-5 GB\n",
    "│   ├── bioactivities: 5-15 GB\n",
    "│   └── analysis_results: 10-50 GB\n",
    "├── Indexes (3-10 GB)\n",
    "│   ├── Primary keys: 500 MB-1 GB\n",
    "│   ├── Foreign keys: 1-2 GB\n",
    "│   └── Search indexes: 2-7 GB\n",
    "└── System Files (2-5 GB)\n",
    "    ├── WAL files: 1-2 GB\n",
    "    ├── Statistics: 500 MB-1 GB\n",
    "    └── Temp files: 500 MB-2 GB\n",
    "```\n",
    "\n",
    "### Container Analysis\n",
    "\n",
    "#### PostgreSQL Container Details\n",
    "```\n",
    "Image: postgres:15 (608.46 MB)\n",
    "Container: mediagent-postgres\n",
    "Port: 5432:5432\n",
    "Volume: postgres_data:/var/lib/postgresql/data\n",
    "```\n",
    "\n",
    "#### Expected Container Health\n",
    "```bash\n",
    "# Healthy container output\n",
    "$ docker ps --format \"table {{.Names}}\\t{{.Status}}\\t{{.Ports}}\"\n",
    "NAMES                STATUS          PORTS\n",
    "mediagent-postgres   Up 2 hours      0.0.0.0:5432->5432/tcp\n",
    "```\n",
    "\n",
    "#### Volume Structure\n",
    "```\n",
    "postgres_data Volume Structure:\n",
    "/var/lib/postgresql/data/\n",
    "├── base/              # Database files\n",
    "│   └── 16388/         # mediagent database\n",
    "├── global/            # Cluster-wide tables\n",
    "├── pg_wal/            # Write-ahead logs\n",
    "├── pg_stat/           # Statistics files\n",
    "├── pg_tblspc/         # Tablespace links\n",
    "└── postgresql.conf    # Configuration\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Table Specifications\n",
    "\n",
    "### 1. compounds - Molecular Data Repository\n",
    "\n",
    "**Purpose**: Central repository for chemical compounds and molecular structures\n",
    "\n",
    "```sql\n",
    "CREATE TABLE compounds (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    chembl_id VARCHAR(20) UNIQUE,           -- ChEMBL identifier (e.g., CHEMBL25)\n",
    "    pubchem_cid BIGINT,                     -- PubChem Compound ID\n",
    "    smiles TEXT NOT NULL,                   -- SMILES notation for structure\n",
    "    molecular_formula VARCHAR(100),         -- Chemical formula (e.g., C8H9NO2)\n",
    "    molecular_weight DECIMAL(10,4),         -- Molecular weight in Daltons\n",
    "    inchi TEXT,                             -- InChI identifier\n",
    "    inchi_key VARCHAR(27),                  -- InChI key for fast lookups\n",
    "    compound_name VARCHAR(255),             -- Common/IUPAC name\n",
    "    canonical_smiles TEXT,                  -- Canonical SMILES representation\n",
    "    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    ");\n",
    "```\n",
    "\n",
    "#### Key Features & Benefits\n",
    "\n",
    "- **🔑 Unique Identifiers**: ChEMBL ID prevents duplicates from pharmaceutical databases\n",
    "- **🧬 Structural Representation**: SMILES notation for chemical structure analysis\n",
    "- **⚖️ Physicochemical Properties**: Molecular weight and formula for drug-likeness assessment\n",
    "- **🔍 Search Optimization**: InChI keys enable rapid molecular similarity searches\n",
    "- **📊 Audit Trail**: Complete timestamp tracking for regulatory compliance\n",
    "\n",
    "#### Data Sources Integration\n",
    "\n",
    "| Source | Purpose | API Endpoint | Data Volume |\n",
    "|--------|---------|--------------|-------------|\n",
    "| **ChEMBL** | Bioactive compounds | https://www.ebi.ac.uk/chembl/ | 2.4M+ compounds |\n",
    "| **PubChem** | Chemical structures | https://pubchem.ncbi.nlm.nih.gov/ | 110M+ compounds |\n",
    "| **RDKit** | Structure validation | Local processing | Computed properties |\n",
    "| **User Input** | Custom molecules | Direct insertion | Research compounds |\n",
    "\n",
    "#### Example Usage\n",
    "```sql\n",
    "-- Insert new compound\n",
    "INSERT INTO compounds (chembl_id, pubchem_cid, smiles, molecular_formula, molecular_weight, compound_name)\n",
    "VALUES ('CHEMBL25', 2244, 'CC(=O)OC1=CC=CC=C1C(=O)O', 'C9H8O4', 180.1574, 'Aspirin');\n",
    "\n",
    "-- Search by molecular weight range\n",
    "SELECT compound_name, molecular_weight, chembl_id\n",
    "FROM compounds \n",
    "WHERE molecular_weight BETWEEN 150 AND 500\n",
    "ORDER BY molecular_weight;\n",
    "\n",
    "-- Find similar compounds by SMILES pattern\n",
    "SELECT compound_name, smiles\n",
    "FROM compounds\n",
    "WHERE smiles LIKE '%CC(=O)O%'\n",
    "LIMIT 10;\n",
    "```\n",
    "\n",
    "### 2. bioactivities - Experimental Data Hub\n",
    "\n",
    "**Purpose**: Stores experimental bioactivity data and compound-target interactions\n",
    "\n",
    "```sql\n",
    "CREATE TABLE bioactivities (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    compound_id INTEGER REFERENCES compounds(id),\n",
    "    target_chembl_id VARCHAR(20),           -- Target protein identifier\n",
    "    activity_type VARCHAR(50),              -- IC50, Ki, EC50, etc.\n",
    "    activity_value DECIMAL(15,6),           -- Numerical activity value\n",
    "    activity_unit VARCHAR(10),              -- nM, μM, mg/mL, etc.\n",
    "    activity_relation VARCHAR(10),          -- =, <, >, <=, >=\n",
    "    assay_chembl_id VARCHAR(20),            -- Assay identifier\n",
    "    assay_type VARCHAR(100),                -- Binding, Functional, ADMET\n",
    "    assay_organism VARCHAR(100),            -- Human, Mouse, Rat, etc.\n",
    "    publication_year INTEGER,               -- Year of publication\n",
    "    journal VARCHAR(255),                   -- Journal name\n",
    "    doi VARCHAR(100),                       -- Digital Object Identifier\n",
    "    confidence_score INTEGER,               -- Data quality score (1-4)\n",
    "    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    ");\n",
    "```\n",
    "\n",
    "#### Activity Types & Measurements\n",
    "\n",
    "| Activity Type | Description | Typical Range | Unit |\n",
    "|---------------|-------------|---------------|------|\n",
    "| **IC50** | Half maximal inhibitory concentration | 0.1 nM - 100 μM | nM, μM |\n",
    "| **Ki** | Inhibition constant | 0.01 nM - 10 μM | nM, μM |\n",
    "| **EC50** | Half maximal effective concentration | 1 nM - 1 mM | nM, μM, mM |\n",
    "| **Kd** | Dissociation constant | 0.1 nM - 100 μM | nM, μM |\n",
    "| **%Inhibition** | Percentage inhibition | 0-100% | % |\n",
    "\n",
    "#### Data Quality Levels\n",
    "\n",
    "| Confidence Score | Description | Data Quality |\n",
    "|------------------|-------------|--------------|\n",
    "| **4** | Direct single protein target | Highest quality |\n",
    "| **3** | Direct protein complex/family | High quality |\n",
    "| **2** | Homologous protein target | Medium quality |\n",
    "| **1** | Subcellular fraction | Lower quality |\n",
    "\n",
    "#### Example Usage\n",
    "```sql\n",
    "-- Insert bioactivity data\n",
    "INSERT INTO bioactivities (compound_id, target_chembl_id, activity_type, activity_value, activity_unit, assay_type, confidence_score)\n",
    "VALUES (1, 'CHEMBL204', 'IC50', 25.5, 'nM', 'Binding', 4);\n",
    "\n",
    "-- Find most potent compounds for a target\n",
    "SELECT c.compound_name, b.activity_value, b.activity_unit\n",
    "FROM bioactivities b\n",
    "JOIN compounds c ON b.compound_id = c.id\n",
    "WHERE b.target_chembl_id = 'CHEMBL204' \n",
    "  AND b.activity_type = 'IC50'\n",
    "  AND b.confidence_score >= 3\n",
    "ORDER BY b.activity_value ASC\n",
    "LIMIT 10;\n",
    "\n",
    "-- Analyze activity distribution\n",
    "SELECT \n",
    "    activity_type,\n",
    "    COUNT(*) as total_activities,\n",
    "    AVG(activity_value) as avg_activity,\n",
    "    MIN(activity_value) as min_activity,\n",
    "    MAX(activity_value) as max_activity\n",
    "FROM bioactivities\n",
    "WHERE confidence_score >= 3\n",
    "GROUP BY activity_type\n",
    "ORDER BY total_activities DESC;\n",
    "```\n",
    "\n",
    "### 3. analysis_results - AI/ML Predictions Storage\n",
    "\n",
    "**Purpose**: Stores AI analysis outputs and machine learning predictions\n",
    "\n",
    "```sql\n",
    "CREATE TABLE analysis_results (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    compound_id INTEGER REFERENCES compounds(id),\n",
    "    analysis_type VARCHAR(100) NOT NULL,    -- ADMET, Toxicity, Target_Prediction, etc.\n",
    "    agent_name VARCHAR(100),                -- Which AI agent performed analysis\n",
    "    model_name VARCHAR(100),                -- DeepSeek-R1, Llama3.3, etc.\n",
    "    model_version VARCHAR(50),              -- Model version tracking\n",
    "    input_data JSONB,                       -- Input parameters as JSON\n",
    "    results JSONB NOT NULL,                 -- Analysis results as JSON\n",
    "    confidence_score DECIMAL(5,4),          -- Prediction confidence (0-1)\n",
    "    processing_time_ms INTEGER,             -- Analysis duration in milliseconds\n",
    "    status VARCHAR(20) DEFAULT 'completed', -- completed, failed, pending\n",
    "    error_message TEXT,                     -- Error details if failed\n",
    "    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    ");\n",
    "```\n",
    "\n",
    "#### Analysis Types & AI Models\n",
    "\n",
    "| Analysis Type | Description | AI Model | Output Format |\n",
    "|---------------|-------------|----------|---------------|\n",
    "| **ADMET** | Absorption, Distribution, Metabolism, Excretion, Toxicity | DeepSeek-R1 | JSON scores (0-1) |\n",
    "| **Target_Prediction** | Molecular target identification | Llama 3.3 | JSON with targets + confidence |\n",
    "| **Toxicity_Assessment** | Safety profile evaluation | DeepSeek-R1 | JSON with toxicity endpoints |\n",
    "| **Drug_Likeness** | Lipinski's Rule of Five compliance | Llama 3.3 | JSON with rule violations |\n",
    "| **Binding_Affinity** | Protein-ligand interaction strength | DeepSeek-R1 | JSON with binding scores |\n",
    "\n",
    "#### JSONB Data Structure Examples\n",
    "\n",
    "```json\n",
    "// ADMET Analysis Result\n",
    "{\n",
    "  \"absorption\": 0.85,\n",
    "  \"distribution\": 0.72,\n",
    "  \"metabolism\": 0.91,\n",
    "  \"excretion\": 0.68,\n",
    "  \"toxicity\": 0.15,\n",
    "  \"blood_brain_barrier\": 0.34,\n",
    "  \"cyp_inhibition\": {\n",
    "    \"CYP1A2\": 0.12,\n",
    "    \"CYP2C9\": 0.08,\n",
    "    \"CYP2D6\": 0.23\n",
    "  }\n",
    "}\n",
    "\n",
    "// Target Prediction Result\n",
    "{\n",
    "  \"predicted_targets\": [\n",
    "    {\n",
    "      \"target_id\": \"CHEMBL204\",\n",
    "      \"target_name\": \"Thrombin\",\n",
    "      \"confidence\": 0.92,\n",
    "      \"binding_mode\": \"competitive\"\n",
    "    },\n",
    "    {\n",
    "      \"target_id\": \"CHEMBL244\",\n",
    "      \"target_name\": \"Factor Xa\",\n",
    "      \"confidence\": 0.78,\n",
    "      \"binding_mode\": \"allosteric\"\n",
    "    }\n",
    "  ],\n",
    "  \"methodology\": \"structure_based_prediction\",\n",
    "  \"total_targets_screened\": 1247\n",
    "}\n",
    "```\n",
    "\n",
    "#### Example Usage\n",
    "```sql\n",
    "-- Insert AI analysis result\n",
    "INSERT INTO analysis_results (compound_id, analysis_type, agent_name, model_name, results, confidence_score, processing_time_ms)\n",
    "VALUES (1, 'ADMET', 'PharmAgent', 'DeepSeek-R1', \n",
    "        '{\"absorption\": 0.85, \"distribution\": 0.72, \"metabolism\": 0.91, \"excretion\": 0.68, \"toxicity\": 0.15}', \n",
    "        0.8934, 1250);\n",
    "\n",
    "-- Query high-confidence ADMET predictions\n",
    "SELECT \n",
    "    c.compound_name,\n",
    "    ar.results->>'absorption' as absorption,\n",
    "    ar.results->>'toxicity' as toxicity,\n",
    "    ar.confidence_score\n",
    "FROM analysis_results ar\n",
    "JOIN compounds c ON ar.compound_id = c.id\n",
    "WHERE ar.analysis_type = 'ADMET'\n",
    "  AND ar.confidence_score > 0.8\n",
    "ORDER BY ar.confidence_score DESC;\n",
    "\n",
    "-- Analyze AI model performance\n",
    "SELECT \n",
    "    model_name,\n",
    "    analysis_type,\n",
    "    COUNT(*) as total_predictions,\n",
    "    AVG(confidence_score) as avg_confidence,\n",
    "    AVG(processing_time_ms) as avg_processing_time\n",
    "FROM analysis_results\n",
    "WHERE status = 'completed'\n",
    "  AND created_at >= CURRENT_DATE - INTERVAL '7 days'\n",
    "GROUP BY model_name, analysis_type\n",
    "ORDER BY total_predictions DESC;\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Performance & Optimization\n",
    "\n",
    "### Database Indexes\n",
    "\n",
    "#### Primary Performance Indexes\n",
    "```sql\n",
    "-- Compound lookup optimization\n",
    "CREATE INDEX idx_compounds_chembl_id ON compounds(chembl_id);\n",
    "CREATE INDEX idx_compounds_smiles ON compounds USING hash(smiles);\n",
    "CREATE INDEX idx_compounds_molecular_weight ON compounds(molecular_weight);\n",
    "CREATE INDEX idx_compounds_inchi_key ON compounds(inchi_key);\n",
    "\n",
    "-- Bioactivity search optimization\n",
    "CREATE INDEX idx_bioactivities_compound_id ON bioactivities(compound_id);\n",
    "CREATE INDEX idx_bioactivities_target ON bioactivities(target_chembl_id);\n",
    "CREATE INDEX idx_bioactivities_type_value ON bioactivities(activity_type, activity_value);\n",
    "CREATE INDEX idx_bioactivities_confidence ON bioactivities(confidence_score DESC);\n",
    "\n",
    "-- Analysis results optimization\n",
    "CREATE INDEX idx_analysis_compound_id ON analysis_results(compound_id);\n",
    "CREATE INDEX idx_analysis_type ON analysis_results(analysis_type);\n",
    "CREATE INDEX idx_analysis_agent ON analysis_results(agent_name);\n",
    "CREATE INDEX idx_analysis_confidence ON analysis_results(confidence_score DESC);\n",
    "CREATE INDEX idx_analysis_created ON analysis_results(created_at DESC);\n",
    "\n",
    "-- JSONB optimization for AI results\n",
    "CREATE INDEX idx_analysis_results_jsonb ON analysis_results USING gin(results);\n",
    "```\n",
    "\n",
    "\n",
    "#### Query Performance Benchmarks\n",
    "\n",
    "| Query Type | Average Time | Index Used | Optimization |\n",
    "|------------|--------------|------------|--------------|\n",
    "| **Compound by ChEMBL ID** | < 1ms | idx_compounds_chembl_id | B-tree unique |\n",
    "| **Bioactivity by target** | < 10ms | idx_bioactivities_target | B-tree |\n",
    "| **AI results by type** | < 5ms | idx_analysis_type | B-tree |\n",
    "| **JSONB property search** | < 50ms | idx_analysis_results_jsonb | GIN |\n",
    "\n",
    "### **Performance Benefits**\n",
    "- **🚀 Fast Compound Lookups**: Sub-millisecond searches by ChEMBL ID\n",
    "- **📊 Efficient Bioactivity Filtering**: Rapid activity type and value queries\n",
    "- **🤖 Agent Result Tracking**: Quick access to specific AI analysis types\n",
    "- **🔍 Confidence-Based Ranking**: Sorted results by prediction confidence\n",
    "\n",
    "### Memory Configuration\n",
    "\n",
    "#### PostgreSQL Configuration Tuning\n",
    "```sql\n",
    "-- Check current settings\n",
    "SHOW shared_buffers;\n",
    "SHOW effective_cache_size;\n",
    "SHOW maintenance_work_mem;\n",
    "\n",
    "-- Recommended settings for drug discovery workload\n",
    "ALTER SYSTEM SET shared_buffers = '256MB';\n",
    "ALTER SYSTEM SET effective_cache_size = '1GB';\n",
    "ALTER SYSTEM SET maintenance_work_mem = '64MB';\n",
    "ALTER SYSTEM SET work_mem = '16MB';\n",
    "```\n",
    "\n",
    "#### Connection Pool Optimization\n",
    "```sql\n",
    "-- Monitor connection usage\n",
    "SELECT \n",
    "    datname,\n",
    "    numbackends,\n",
    "    xact_commit,\n",
    "    xact_rollback,\n",
    "    blks_read,\n",
    "    blks_hit,\n",
    "    tup_returned,\n",
    "    tup_fetched\n",
    "FROM pg_stat_database \n",
    "WHERE datname = 'mediagent';\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## System Integration\n",
    "\n",
    "### Integration Points\n",
    "\n",
    "| Service | Connection Method | Purpose | Configuration |\n",
    "|---------|-------------------|---------|---------------|\n",
    "| **n8n Workflows** | PostgreSQL Node | Data orchestration | Host: mediagent-postgres:5432 |\n",
    "| **Ollama LLMs** | HTTP API → Database | AI result storage | Via n8n workflows |\n",
    "| **Redis Cache** | Shared caching | Query acceleration | Cache frequent lookups |\n",
    "| **FastAPI** | SQLAlchemy ORM | REST API access | Connection pooling |\n",
    "\n",
    "### Data Integration Workflow\n",
    "\n",
    "#### 1. External Data Ingestion\n",
    "```sql\n",
    "-- ChEMBL data import workflow\n",
    "WITH new_compounds AS (\n",
    "    SELECT DISTINCT\n",
    "        chembl_id,\n",
    "        smiles,\n",
    "        molecular_formula,\n",
    "        molecular_weight,\n",
    "        compound_name\n",
    "    FROM staging_chembl_data\n",
    "    WHERE chembl_id NOT IN (SELECT chembl_id FROM compounds WHERE chembl_id IS NOT NULL)\n",
    ")\n",
    "INSERT INTO compounds (chembl_id, smiles, molecular_formula, molecular_weight, compound_name)\n",
    "SELECT * FROM new_compounds;\n",
    "```\n",
    "\n",
    "#### 2. AI Analysis Pipeline\n",
    "```sql\n",
    "-- Trigger AI analysis for new compounds\n",
    "SELECT \n",
    "    id,\n",
    "    chembl_id,\n",
    "    smiles,\n",
    "    molecular_weight\n",
    "FROM compounds c\n",
    "WHERE NOT EXISTS (\n",
    "    SELECT 1 FROM analysis_results ar \n",
    "    WHERE ar.compound_id = c.id \n",
    "    AND ar.analysis_type = 'ADMET'\n",
    ")\n",
    "LIMIT 100;\n",
    "```\n",
    "\n",
    "#### 3. Result Aggregation\n",
    "```sql\n",
    "-- Comprehensive compound analysis view\n",
    "CREATE VIEW compound_analysis_summary AS\n",
    "SELECT \n",
    "    c.id,\n",
    "    c.compound_name,\n",
    "    c.chembl_id,\n",
    "    c.molecular_weight,\n",
    "    COUNT(DISTINCT b.id) as bioactivity_count,\n",
    "    COUNT(DISTINCT ar.id) as analysis_count,\n",
    "    AVG(ar.confidence_score) as avg_ai_confidence,\n",
    "    MAX(ar.created_at) as last_analysis_date\n",
    "FROM compounds c\n",
    "LEFT JOIN bioactivities b ON c.id = b.compound_id\n",
    "LEFT JOIN analysis_results ar ON c.id = ar.compound_id\n",
    "GROUP BY c.id, c.compound_name, c.chembl_id, c.molecular_weight;\n",
    "```\n",
    "\n",
    "### API Integration Examples\n",
    "\n",
    "#### FastAPI Database Connection\n",
    "```python\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "# Database connection\n",
    "DATABASE_URL = \"postgresql://admin:password@mediagent-postgres:5432/mediagent\"\n",
    "engine = create_engine(DATABASE_URL)\n",
    "SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n",
    "\n",
    "# Example API endpoint\n",
    "@app.get(\"/compounds/{compound_id}\")\n",
    "async def get_compound(compound_id: int):\n",
    "    db = SessionLocal()\n",
    "    compound = db.query(Compound).filter(Compound.id == compound_id).first()\n",
    "    return compound\n",
    "```\n",
    "\n",
    "#### n8n Workflow Integration\n",
    "```javascript\n",
    "// n8n PostgreSQL node configuration\n",
    "{\n",
    "  \"operation\": \"executeQuery\",\n",
    "  \"query\": \"SELECT * FROM compounds WHERE molecular_weight BETWEEN $1 AND $2\",\n",
    "  \"parameters\": {\n",
    "    \"min_weight\": 150,\n",
    "    \"max_weight\": 500\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Commands Reference\n",
    "\n",
    "### Database Administration\n",
    "\n",
    "#### Connection Management\n",
    "```bash\n",
    "# Connect to database\n",
    "docker exec -it mediagent-postgres psql -U admin -d mediagent\n",
    "\n",
    "# Connect with specific command\n",
    "docker exec -it mediagent-postgres psql -U admin -d mediagent -c \"SELECT COUNT(*) FROM compounds;\"\n",
    "\n",
    "# Run SQL file\n",
    "docker exec -i mediagent-postgres psql -U admin -d mediagent < queries.sql\n",
    "```\n",
    "\n",
    "#### Database Backup & Restore\n",
    "```bash\n",
    "# Create full database backup\n",
    "docker exec -it mediagent-postgres pg_dump -U admin -d mediagent > mediagent_backup.sql\n",
    "\n",
    "# Create compressed backup\n",
    "docker exec -it mediagent-postgres pg_dump -U admin -d mediagent | gzip > mediagent_backup.sql.gz\n",
    "\n",
    "# Restore from backup\n",
    "docker exec -i mediagent-postgres psql -U admin -d mediagent < mediagent_backup.sql\n",
    "\n",
    "# Table-specific backup\n",
    "docker exec -it mediagent-postgres pg_dump -U admin -d mediagent -t compounds > compounds_backup.sql\n",
    "```\n",
    "\n",
    "#### Performance Monitoring\n",
    "```sql\n",
    "-- Active connections\n",
    "SELECT \n",
    "    pid,\n",
    "    usename,\n",
    "    application_name,\n",
    "    state,\n",
    "    query_start,\n",
    "    query\n",
    "FROM pg_stat_activity\n",
    "WHERE state = 'active';\n",
    "\n",
    "-- Table sizes\n",
    "SELECT \n",
    "    schemaname,\n",
    "    tablename,\n",
    "    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size,\n",
    "    pg_size_pretty(pg_relation_size(schemaname||'.'||tablename)) as table_size,\n",
    "    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename) - pg_relation_size(schemaname||'.'||tablename)) as index_size\n",
    "FROM pg_tables \n",
    "WHERE schemaname = 'public'\n",
    "ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;\n",
    "\n",
    "-- Index usage statistics\n",
    "SELECT \n",
    "    schemaname,\n",
    "    tablename,\n",
    "    indexname,\n",
    "    idx_tup_read,\n",
    "    idx_tup_fetch,\n",
    "    idx_scan\n",
    "FROM pg_stat_user_indexes\n",
    "ORDER BY idx_scan DESC;\n",
    "```\n",
    "\n",
    "### Data Management\n",
    "\n",
    "#### Data Quality Checks\n",
    "```sql\n",
    "-- Check for duplicate ChEMBL IDs\n",
    "SELECT chembl_id, COUNT(*) as duplicate_count\n",
    "FROM compounds\n",
    "WHERE chembl_id IS NOT NULL\n",
    "GROUP BY chembl_id\n",
    "HAVING COUNT(*) > 1;\n",
    "\n",
    "-- Validate SMILES notation\n",
    "SELECT id, smiles\n",
    "FROM compounds\n",
    "WHERE smiles IS NULL OR smiles = '' OR LENGTH(smiles) < 3;\n",
    "\n",
    "-- Check bioactivity data integrity\n",
    "SELECT \n",
    "    COUNT(*) as total_bioactivities,\n",
    "    COUNT(DISTINCT compound_id) as unique_compounds,\n",
    "    COUNT(DISTINCT target_chembl_id) as unique_targets\n",
    "FROM bioactivities;\n",
    "\n",
    "-- Verify AI analysis completeness\n",
    "SELECT \n",
    "    analysis_type,\n",
    "    COUNT(*) as total_analyses,\n",
    "    COUNT(DISTINCT compound_id) as unique_compounds,\n",
    "    AVG(confidence_score) as avg_confidence\n",
    "FROM analysis_results\n",
    "GROUP BY analysis_type\n",
    "ORDER BY total_analyses DESC;\n",
    "```\n",
    "\n",
    "#### Data Maintenance\n",
    "```sql\n",
    "-- Update compound molecular weights\n",
    "UPDATE compounds \n",
    "SET molecular_weight = 180.1574 \n",
    "WHERE chembl_id = 'CHEMBL25';\n",
    "\n",
    "-- Clean up failed AI analyses\n",
    "DELETE FROM analysis_results \n",
    "WHERE status = 'failed' \n",
    "  AND created_at < CURRENT_DATE - INTERVAL '7 days';\n",
    "\n",
    "-- Refresh analysis timestamps\n",
    "UPDATE analysis_results \n",
    "SET updated_at = CURRENT_TIMESTAMP \n",
    "WHERE status = 'completed';\n",
    "```\n",
    "\n",
    "### Advanced Queries\n",
    "\n",
    "#### Compound Discovery Analytics\n",
    "```sql\n",
    "-- Find compounds with high bioactivity and good ADMET profile\n",
    "WITH admet_scores AS (\n",
    "    SELECT \n",
    "        compound_id,\n",
    "        (results->>'absorption')::float as absorption,\n",
    "        (results->>'toxicity')::float as toxicity,\n",
    "        confidence_score\n",
    "    FROM analysis_results\n",
    "    WHERE analysis_type = 'ADMET'\n",
    "      AND confidence_score > 0.8\n",
    "),\n",
    "potent_compounds AS (\n",
    "    SELECT \n",
    "        compound_id,\n",
    "        MIN(activity_value) as best_activity\n",
    "    FROM bioactivities\n",
    "    WHERE activity_type = 'IC50'\n",
    "      AND activity_value < 100\n",
    "      AND confidence_score >= 3\n",
    "    GROUP BY compound_id\n",
    ")\n",
    "SELECT \n",
    "    c.compound_name,\n",
    "    c.chembl_id,\n",
    "    c.molecular_weight,\n",
    "    pc.best_activity,\n",
    "    ads.absorption,\n",
    "    ads.toxicity,\n",
    "    ads.confidence_score\n",
    "FROM compounds c\n",
    "JOIN potent_compounds pc ON c.id = pc.compound_id\n",
    "JOIN admet_scores ads ON c.id = ads.compound_id\n",
    "WHERE ads.absorption > 0.7 AND ads.toxicity < 0.3\n",
    "ORDER BY pc.best_activity ASC, ads.confidence_score DESC\n",
    "LIMIT 20;\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Monitoring & Maintenance\n",
    "\n",
    "### Health Monitoring\n",
    "\n",
    "#### Database Health Checks\n",
    "```sql\n",
    "-- Overall database health\n",
    "SELECT \n",
    "    'Database Size' as metric,\n",
    "    pg_size_pretty(pg_database_size('mediagent')) as value\n",
    "UNION ALL\n",
    "SELECT \n",
    "    'Active Connections' as metric,\n",
    "    COUNT(*)::text as value\n",
    "FROM pg_stat_activity\n",
    "WHERE state = 'active'\n",
    "UNION ALL\n",
    "SELECT \n",
    "    'Total Tables' as metric,\n",
    "    COUNT(*)::text as value\n",
    "FROM information_schema.tables\n",
    "WHERE table_schema = 'public';\n",
    "\n",
    "-- Data freshness check\n",
    "SELECT \n",
    "    'compounds' as table_name,\n",
    "    COUNT(*) as total_rows,\n",
    "    MAX(created_at) as last_insert,\n",
    "    MIN(created_at) as first_insert\n",
    "FROM compounds\n",
    "UNION ALL\n",
    "SELECT \n",
    "    'bioactivities' as table_name,\n",
    "    COUNT(*) as total_rows,\n",
    "    MAX(created_at) as last_insert,\n",
    "    MIN(created_at) as first_insert\n",
    "FROM bioactivities\n",
    "UNION ALL\n",
    "SELECT \n",
    "    'analysis_results' as table_name,\n",
    "    COUNT(*) as total_rows,\n",
    "    MAX(created_at) as last_insert,\n",
    "    MIN(created_at) as first_insert\n",
    "FROM analysis_results;\n",
    "```\n",
    "\n",
    "#### Performance Monitoring\n",
    "```sql\n",
    "-- Slow query identification\n",
    "SELECT \n",
    "    query,\n",
    "    calls,\n",
    "    total_time,\n",
    "    mean_time,\n",
    "    min_time,\n",
    "    max_time\n",
    "FROM pg_stat_statements\n",
    "WHERE mean_time > 100\n",
    "ORDER BY mean_time DESC\n",
    "LIMIT 10;\n",
    "\n",
    "-- Lock monitoring\n",
    "SELECT \n",
    "    pid,\n",
    "    usename,\n",
    "    mode,\n",
    "    locktype,\n",
    "    relation::regclass,\n",
    "    page,\n",
    "    tuple,\n",
    "    virtualxid,\n",
    "    transactionid,\n",
    "    granted\n",
    "FROM pg_locks\n",
    "WHERE NOT granted;\n",
    "```\n",
    "\n",
    "### Automated Maintenance\n",
    "\n",
    "#### Daily Maintenance Tasks\n",
    "```sql\n",
    "-- Statistics update\n",
    "ANALYZE compounds;\n",
    "ANALYZE bioactivities;\n",
    "ANALYZE analysis_results;\n",
    "\n",
    "-- Vacuum for performance\n",
    "VACUUM ANALYZE compounds;\n",
    "VACUUM ANALYZE bioactivities;\n",
    "VACUUM ANALYZE analysis_results;\n",
    "\n",
    "-- Reindex for optimal performance\n",
    "REINDEX INDEX idx_compounds_chembl_id;\n",
    "REINDEX INDEX idx_bioactivities_compound_id;\n",
    "REINDEX INDEX idx_analysis_compound_id;\n",
    "```\n",
    "\n",
    "#### Weekly Maintenance Tasks\n",
    "```sql\n",
    "-- Comprehensive vacuum\n",
    "VACUUM FULL ANALYZE compounds;\n",
    "VACUUM FULL ANALYZE bioactivities;\n",
    "VACUUM FULL ANALYZE analysis_results;\n",
    "\n",
    "-- Check for unused indexes\n",
    "SELECT \n",
    "    schemaname,\n",
    "    tablename,\n",
    "    indexname,\n",
    "    idx_scan,\n",
    "    idx_tup_read,\n",
    "    idx_tup_fetch\n",
    "FROM pg_stat_user_indexes\n",
    "WHERE idx_scan = 0\n",
    "ORDER BY pg_relation_size(indexrelid) DESC;\n",
    "```\n",
    "\n",
    "### Alert System\n",
    "\n",
    "#### Critical Alerts\n",
    "```sql\n",
    "-- Database size alert (>80% capacity)\n",
    "SELECT \n",
    "    CASE \n",
    "        WHEN pg_database_size('mediagent') > 80 * 1024 * 1024 * 1024 THEN 'CRITICAL: Database size exceeds 80GB'\n",
    "        ELSE 'OK: Database size within limits'\n",
    "    END as alert_status,\n",
    "    pg_size_pretty(pg_database_size('mediagent')) as current_size;\n",
    "\n",
    "-- Connection limit alert\n",
    "SELECT \n",
    "    CASE \n",
    "        WHEN COUNT(*) > 80 THEN 'WARNING: High connection count'\n",
    "        ELSE 'OK: Connection count normal'\n",
    "    END as alert_status,\n",
    "    COUNT(*) as active_connections\n",
    "FROM pg_stat_activity\n",
    "WHERE state = 'active';\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### **Integration Points**\n",
    "\n",
    "| Component | Connection Method | Purpose |\n",
    "|-----------|-------------------|---------|\n",
    "| **n8n Workflows** | PostgreSQL connector | Automated data ingestion & processing |\n",
    "| **Ollama LLMs** | HTTP API calls | AI analysis result storage |\n",
    "| **Redis Cache** | Key-value caching | High-frequency query optimization |\n",
    "| **FastAPI** | SQLAlchemy ORM | REST API data access |\n",
    "| **React Frontend** | GraphQL/REST | User interface data display |\n",
    "\n",
    "---\n",
    "\n",
    "## **🔧 Database Maintenance & Monitoring**\n",
    "\n",
    "### **Health Check Queries**\n",
    "```sql\n",
    "-- Database size and growth\n",
    "SELECT \n",
    "    pg_size_pretty(pg_database_size('mediagent')) as database_size,\n",
    "    pg_size_pretty(pg_total_relation_size('compounds')) as compounds_size,\n",
    "    pg_size_pretty(pg_total_relation_size('bioactivities')) as bioactivities_size,\n",
    "    pg_size_pretty(pg_total_relation_size('analysis_results')) as analysis_results_size;\n",
    "\n",
    "-- Recent activity summary\n",
    "SELECT \n",
    "    DATE(created_at) as date,\n",
    "    COUNT(*) as new_compounds\n",
    "FROM compounds \n",
    "WHERE created_at >= CURRENT_DATE - INTERVAL '7 days'\n",
    "GROUP BY DATE(created_at)\n",
    "ORDER BY date DESC;\n",
    "\n",
    "-- AI analysis performance\n",
    "SELECT \n",
    "    analysis_type,\n",
    "    COUNT(*) as total_analyses,\n",
    "    AVG(confidence_score) as avg_confidence,\n",
    "    AVG(processing_time_ms) as avg_processing_time\n",
    "FROM analysis_results\n",
    "WHERE created_at >= CURRENT_DATE - INTERVAL '24 hours'\n",
    "GROUP BY analysis_type\n",
    "ORDER BY total_analyses DESC;\n",
    "```\n",
    "\n",
    "### **Automated Maintenance**\n",
    "- **🔄 Daily Statistics**: Automated collection of database growth metrics\n",
    "- **🧹 Cleanup Jobs**: Removal of low-confidence predictions and temporary data\n",
    "- **📊 Performance Tuning**: Index usage analysis and optimization\n",
    "- **🔐 Backup Strategy**: Daily full backups with point-in-time recovery\n",
    "\n",
    "---\n",
    "\n",
    "## **🚀 Next Development Phase Preparation**\n",
    "\n",
    "### **Immediate Ready Features**\n",
    "1. **Multi-Agent Integration**: Database schema supports concurrent AI agents\n",
    "2. **Real-Time Processing**: Redis caching optimized for high-frequency operations\n",
    "3. **API Development**: Schema designed for FastAPI REST endpoints\n",
    "4. **Frontend Integration**: GraphQL-ready structure for React components\n",
    "\n",
    "### **Scalability Considerations**\n",
    "- **🔧 Partitioning Strategy**: Ready for table partitioning on compound_id\n",
    "- **📊 Analytics Queries**: Optimized for complex drug discovery analytics\n",
    "- **🌐 Cloud Migration**: PostgreSQL configuration compatible with Google Cloud SQL\n",
    "- **⚡ Performance Monitoring**: Built-in metrics for database performance tracking\n",
    "\n",
    "### **Security & Compliance**\n",
    "- **🔐 Access Control**: Role-based permissions for different user types\n",
    "- **📋 Audit Trail**: Complete timestamp tracking for regulatory compliance\n",
    "- **🛡️ Data Integrity**: Foreign key constraints and validation rules\n",
    "- **💾 Backup & Recovery**: Automated backup strategy with encryption\n",
    "\n",
    "---\n",
    "\n",
    "## **📈 Database Statistics & Capacity**\n",
    "\n",
    "### **Current Capacity Planning**\n",
    "- **Compounds**: Designed for 1M+ molecular structures\n",
    "- **Bioactivities**: Optimized for 10M+ experimental data points\n",
    "- **Analysis Results**: Scalable to 100M+ AI predictions\n",
    "- **Storage**: Efficient JSONB usage for flexible data structures\n",
    "\n",
    "### **Performance Benchmarks**\n",
    "- **Compound Lookup**: < 1ms average response time\n",
    "- **Bioactivity Queries**: < 10ms for filtered searches\n",
    "- **AI Result Storage**: < 5ms for prediction insertion\n",
    "- **Complex Analytics**: < 100ms for multi-table joins\n",
    "\n",
    "---\n",
    "\n",
    "## **🎯 Success Metrics & KPIs**\n",
    "\n",
    "### **Database Performance KPIs**\n",
    "- **Query Response Time**: < 100ms for 95% of queries\n",
    "- **Concurrent Users**: Support for 100+ simultaneous connections\n",
    "- **Data Integrity**: 99.99% consistency across all relationships\n",
    "- **Uptime**: 99.9% availability for continuous AI processing\n",
    "\n",
    "### **Drug Discovery Metrics**\n",
    "- **Compound Processing**: 1000+ compounds analyzed per hour\n",
    "- **Prediction Accuracy**: > 85% confidence for ADMET predictions\n",
    "- **Data Quality**: > 95% successful data validation rate\n",
    "- **Agent Efficiency**: < 500ms average AI processing time\n",
    "\n",
    "This comprehensive database architecture provides the foundation for enterprise-level drug discovery operations, ready to scale with growing computational demands and evolving AI capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9495e0f8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
